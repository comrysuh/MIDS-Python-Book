{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e1384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Exercise 9.1 - another iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76a514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 9.1\n",
    "import numpy as np\n",
    "\n",
    "def update_weights_linear(data, target, weights, epsilon):    \n",
    "    pred = np.matmul(data, weights.T)\n",
    "    Res = target - pred\n",
    "    Qvalue = -np.matmul(Res.T, data)   \n",
    "    print('\\nThe derivatives are:\\n', Qvalue)\n",
    "    newweights = weights - epsilon * Qvalue\n",
    "\n",
    "    return newweights\n",
    "\n",
    "X = np.array([[1, 1]])\n",
    "Target = np.array([[0.5, 0]])\n",
    "W = np.array([[0.5, 0.5], [0.25, 0.25]])\n",
    "epsilon = 0.1\n",
    "\n",
    "newW = update_weights_linear(X, Target, W, epsilon)\n",
    "print('The weights after one iteration are:\\n', newW)\n",
    "Y1 = np.matmul(X, newW.T)\n",
    "print('The predictions after one iteration are:\\n', Y1)\n",
    "error1 = np.sum((Target - Y1)**2)/2\n",
    "print('The error after one iteration is:', np.round(error1,2))\n",
    "\n",
    "newW = update_weights_linear(X, Target, newW, epsilon)\n",
    "print('The weights after two iterations are:\\n', newW)\n",
    "Y1 = np.matmul(X, newW.T)\n",
    "print('The predictions after two iterations are:\\n', Y1)\n",
    "error1 = np.sum((Target - Y1)**2)/2\n",
    "print('The error after two iterations is:', np.round(error1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3d8774-c333-4fe8-8e23-de869eb5f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Exercise 9.2 - the new function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc10e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 9.2 - the new function\n",
    "def update_weights_linear1(data, target, weights, epsilon):\n",
    "    \n",
    "    for ind, (x, t) in enumerate(zip(data, target)):\n",
    "        x = x[np.newaxis,:]\n",
    "        t = t[np.newaxis,:]\n",
    "        print(f'The index of the data item: {ind+1}')\n",
    "        pred = np.matmul(x, weights.T)\n",
    "        Res = t-pred\n",
    "        error0 = np.sum((t - pred)**2)/2\n",
    "        print('The error is:', error0)\n",
    "        Qvalue = np.matmul(-x.T, Res)   \n",
    "        print('The derivatives are:\\n', Qvalue)\n",
    "        weights = weights - epsilon * Qvalue\n",
    "\n",
    "    return weights\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503897fd-2e28-4a9f-b3f6-a8153330f135",
   "metadata": {},
   "source": [
    "#### Exercise 9.2 - using the new function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46365e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 9. - using the new function\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1, 1],[2, 2]])\n",
    "print('The data is:\\n', X)\n",
    "Target = np.array([[0.5, 0],[1, 0.5]])\n",
    "W = np.array([[0.5, 0.5], [0.25, 0.25]])\n",
    "epsilon = 0.1\n",
    "\n",
    "Y0 = np.matmul(X, W.T)\n",
    "print('The initial predictions are:\\n', Y0)\n",
    "error0 = np.sum((Target - Y0)**2)/2\n",
    "print('The initial error is:', error0)\n",
    "\n",
    "newW = update_weights_linear1(X, Target, W, epsilon)\n",
    "\n",
    "Y1 = np.matmul(X, newW.T)\n",
    "print('The final predictions are:\\n', Y1)\n",
    "error1 = np.sum((Target - Y1)**2)/2\n",
    "print('The final error is:', np.round(error1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb29e453-0e80-4934-91e6-73be4f89059a",
   "metadata": {},
   "source": [
    "#### Exercise 9.3 - the new function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9299b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 9.3 - the new function\n",
    "def sigmoid(X):\n",
    "    return 1/(np.exp(-X)+1)\n",
    "\n",
    "def update_weights_sigmoid(data, target, weights, epsilon, iterations):\n",
    "    E = []\n",
    "    for iter in range(iterations): \n",
    "    \n",
    "        A0 = np.matmul(data, weights.T)\n",
    "        pred = np.round(sigmoid(A0),3)\n",
    "        Res = target - pred\n",
    "        error = np.sum((Res)**2)/2\n",
    "        E.append(error)\n",
    "        delta = -Res * (sigmoid(A0) * (1-sigmoid(A0)))\n",
    "        Qvalue = np.matmul(delta.T, data)   \n",
    "        weights = weights - epsilon * Qvalue\n",
    "\n",
    "    return weights, E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b46c167-3b41-4ab9-b2ca-829e9290e901",
   "metadata": {},
   "source": [
    "#### Exercise 9.3 - part (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fc33bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 9.3 - part (1)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.array([[1, 1]])\n",
    "Target = np.array([[0.5, 0]])\n",
    "W = np.array([[0.5, 0.5], [0.25, 0.25]])\n",
    "epsilon = 0.1\n",
    "iterations = 500\n",
    "\n",
    "A0 = np.matmul(X,W.T)\n",
    "Y0 = np.round(sigmoid(A0),3)\n",
    "init_error = np.sum((Target - Y0)**2)/2\n",
    "print('Initial error is:',np.round(init_error,3))\n",
    "\n",
    "newW, E_list = update_weights_sigmoid(X, Target, W, epsilon, iterations)\n",
    "print('The updated weights after 500 iteration are:\\n', newW)\n",
    "A1 = np.matmul(X, newW.T)\n",
    "Y1 = np.round(sigmoid(A1),3)\n",
    "print('The predictions are:\\n', Y1)\n",
    "error = np.sum((Target - Y1)**2)/2\n",
    "print('The final error is:', np.round(error,4))\n",
    "#Alternately use print('The final error is:', np.round(E_list[-1],4))\n",
    "\n",
    "plt.plot(range(1, iterations+1), E_list)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Error vs. Number of Iterations')\n",
    "plt.savefig('error_curve1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc78822-5e4e-486e-878c-7243ffe6c911",
   "metadata": {},
   "source": [
    "#### Exercise 9.3 - part (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d64169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 9.3 - part (2)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.array([[2, 2]])\n",
    "Target = np.array([[1, 0.5]])\n",
    "W = np.array([[0.5, 0.5], [0.25, 0.25]])\n",
    "epsilon = 0.1\n",
    "iterations = 500\n",
    "\n",
    "A0 = np.matmul(X,W.T)\n",
    "Y0 = np.round(sigmoid(A0),3)\n",
    "init_error = np.sum((Target - Y0)**2)/2\n",
    "print('Initial error is:',np.round(init_error,3))\n",
    "\n",
    "newW, E_list = update_weights_sigmoid(X, Target, W, epsilon, iterations)\n",
    "print('The updated weights after 500 iteration are:\\n', newW)\n",
    "A1 = np.matmul(X, newW.T)\n",
    "Y1 = np.round(sigmoid(A1),3)\n",
    "print('The predictions are:\\n', Y1)\n",
    "error = np.sum((Target - Y1)**2)/2\n",
    "print('The final error is:', np.round(error,4))\n",
    "#Alternately use print('The final error is:', np.round(E_list[-1],4))\n",
    "\n",
    "plt.plot(range(1, iterations+1), E_list)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Error vs. Number of Iterations')\n",
    "plt.savefig('error_curve2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055c6b0e-ea78-4893-919b-0615fe7d6e55",
   "metadata": {},
   "source": [
    "#### Exercise 9.4 - the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abebf4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 9.4 - the function\n",
    "def sigmoid(X):    \n",
    "    return 1/(np.exp(-X)+1)\n",
    "\n",
    "def update_weights_sigmoid_2data(data, target, weights, epsilon, iterations):\n",
    "    E = []\n",
    "    \n",
    "    for iter in range(iterations): \n",
    "        for ind, (x, t) in enumerate(zip(data, target)):\n",
    "            x = x[np.newaxis,:]\n",
    "            t = t[np.newaxis,:]\n",
    "            A0 = np.matmul(x,weights.T)\n",
    "            pred = np.round(sigmoid(A0),3)\n",
    "            Res = t-pred\n",
    "            error = np.sum(Res**2)/2\n",
    "            delta = -Res * (sigmoid(A0) * (1-sigmoid(A0)))\n",
    "            Qvalue = np.matmul(delta.T, x)   \n",
    "            weights = weights - epsilon * Qvalue\n",
    "        A1 = np.matmul(data,weights.T)\n",
    "        pred1 = np.round(sigmoid(A1),3)\n",
    "        Res1 = target - pred1\n",
    "        error1 = np.sum(Res1**2)/2\n",
    "        if iter == 0:\n",
    "            print('First iteration error is: ',np.round(error1,4))\n",
    "        E.append(error1)\n",
    "\n",
    "    return weights, E\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f6e186-7e8c-4d73-832a-34738cd72f11",
   "metadata": {},
   "source": [
    "#### Exercise 9.4 - using the function on 2 data items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04de26a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 9.4 - using the function on 2 data items\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.array([[1, 1],[2, 2]])\n",
    "Target = np.array([[0.5, 0],[1, 0.5]])\n",
    "W = np.array([[0.5, 0.5], [0.25, 0.25]])\n",
    "epsilon = 0.1\n",
    "iterations = 500\n",
    "\n",
    "A_init = np.matmul(X, W.T)\n",
    "Y_init = np.round(sigmoid(A_init),3)\n",
    "error_init = np.sum((Target - Y_init)**2)/2\n",
    "print('The initial error is:', np.round(error_init,4))\n",
    "\n",
    "newW, E_list = update_weights_sigmoid_2data(X, Target, W, epsilon, iterations)\n",
    "print('The updated weights after 500 iteration are:\\n', newW)\n",
    "A1 = np.matmul(X, newW.T)\n",
    "Y1 = np.round(sigmoid(A1),3)\n",
    "print('The final predictions are:\\n', Y1)\n",
    "print('The final error is:', np.round(E_list[-1],4))\n",
    "\n",
    "plt.plot(range(1, iterations+1), E_list)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Error vs. Number of Iterations')\n",
    "plt.savefig('error_curve3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d00cd59-cb25-44f9-9693-4e43a1ddc58b",
   "metadata": {},
   "source": [
    "#### Exercise 9.5 - first function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b668e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 9.5 - first function\n",
    "def prediction(data, weights_1, weights_2): \n",
    "    A_1 = np.matmul(data, weights_1.T)\n",
    "    Z_1 = A_1\n",
    "    \n",
    "    A_2 = np.matmul(Z_1, weights_2.T)\n",
    "    Y = np.round(A_2,3)\n",
    "    \n",
    "    return Y, A_2, Z_1, A_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fd84b8-b7e4-49a2-81c9-b632446f3ff1",
   "metadata": {},
   "source": [
    "#### Exercise 9.5 - second function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f42052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 9.5 - second function\n",
    "def update_weights(data, target, weights_1, weights_2, epsilon):\n",
    "    Y, A_2, Z_1, A_1 = prediction(data, weights_1, weights_2)\n",
    "    \n",
    "    delta_2 = target - Y\n",
    "    newweights_2 = weights_2 + epsilon * Z_1 * delta_2.T\n",
    "    print('delta_2 is:\\n',delta_2)\n",
    "   \n",
    "    ga_1  = np.array([[1,1]])\n",
    "    print('ga_1 is:\\n', ga_1)\n",
    "    \n",
    "    delta_1 = (np.matmul(delta_2, weights_2)) * ga_1\n",
    "    print('delta_1 is\\n', delta_1)\n",
    "    newweights_1 = weights_1 + epsilon * data * delta_1.T\n",
    "    \n",
    "    return newweights_1, newweights_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04ed111-919d-49a4-b581-8d83e6eeaa35",
   "metadata": {},
   "source": [
    "#### Exercise 9.5 - using the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313d6c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 9.5 - using the functions\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1, 0]])\n",
    "print('The data is:',X)\n",
    "W_1 = np.array([[0.5, 0.5], [0.25, 0.25]])\n",
    "W_2 = np.array([[0.25, 0.25], [0.5, 0.5]])\n",
    "Target = np.array([[0.25, 0.5]])\n",
    "epsilon = 0.1\n",
    "\n",
    "Y0 = prediction(X, W_1, W_2)[0]\n",
    "error0 = np.sum((Target - Y0)**2)/2\n",
    "print('The initial error is:', np.round(error0,3))\n",
    "\n",
    "newW_1, newW_2 = update_weights(X, Target, W_1, W_2, epsilon)\n",
    "print('The newW_1 is:\\n', newW_1)\n",
    "print('The newW_2 is:\\n', newW_2)\n",
    "\n",
    "Y, A_2, Z_1, A_1 = prediction(X, newW_1, newW_2)\n",
    "print('The predictions are:\\n', Y)\n",
    "error1 = np.sum((Target - Y)**2)/2\n",
    "print('The error after one iteration is:', np.round(error1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dc7efe-e3bf-490f-9a16-ecc9cab5b07f",
   "metadata": {},
   "source": [
    "#### Exercise 9.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736e85dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 9.6\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train = np.array([[-2], [-1.3], [-1], [0], [1], [1.8], [2]])\n",
    "y_train = np.array([3.2, 1.2, 1.6, 0.1, 0.9, 3.0, 4.2])\n",
    "X_test = np.array([[-1.2], [2.6]])\n",
    "y_test = np.array([1.2, 6.8])\n",
    "\n",
    "mlpreg = MLPRegressor(hidden_layer_sizes=(5), activation = 'relu', solver = 'sgd', max_iter=1000, verbose = True, random_state=1)\n",
    "#mlpreg = MLPRegressor(hidden_layer_sizes=(10), activation = 'relu', solver = 'sgd', max_iter=500, verbose = True, random_state=1)\n",
    "#mlpreg = MLPRegressor(hidden_layer_sizes=(5,3), activation = 'relu', solver = 'sgd', max_iter=500, verbose = True, random_state=1)\n",
    "#mlpreg = MLPRegressor(hidden_layer_sizes=(5,3,2), activation = 'relu', solver = 'sgd', max_iter=1000, verbose = True, random_state=1)\n",
    "mlpreg.fit(X_train, y_train)\n",
    "biases = [np.round(bias, 2) for bias in mlpreg.intercepts_]\n",
    "print('The trained list of biases is:\\n', biases)\n",
    "weights = [np.round(coef, 2) for coef in mlpreg.coefs_]\n",
    "print('The trained weights are:\\n', weights)\n",
    "\n",
    "y_pred = mlpreg.predict(X_test)\n",
    "print('The predicted values are:\\n', np.round(y_pred,2))\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('The mean squared error on the test set is:\\n', np.round(mse, 3))\n",
    "loss = mlpreg.loss_curve_\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "ax[0].scatter(X_train, y_train, color='blue', marker='s', label='Training data')\n",
    "ax[0].scatter(X_test, y_test, color='green', marker='x', label='Test data')\n",
    "ax[0].set_xlabel('X')\n",
    "ax[0].set_ylabel('y')\n",
    "ax[0].legend()\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].plot(loss, label='Training Loss')\n",
    "ax[1].set_xlabel('Iterations')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].legend(loc='lower left')\n",
    "ax[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('data_and_learning_curve.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27cd72c-634a-4d52-9a4c-a8f262bac85e",
   "metadata": {},
   "source": [
    "#### Exercise 9.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a05c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 9.7\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "X = np.random.randn(200, 2)\n",
    "print('the first 5 data:\\n',X[:5])\n",
    "y = np.logical_xor(X[:, 0] > 0, X[:, 1] > 0)\n",
    "print('The first five target values:\\n', y[:5])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "\n",
    "mlpclf = MLPClassifier(hidden_layer_sizes=(10), activation = 'relu', solver = 'sgd', max_iter=3000, verbose=True)    \n",
    "#mlpclf = MLPClassifier(hidden_layer_sizes=(50), activation = 'relu', solver = 'sgd', max_iter=3000, verbose=True)\n",
    "#mlpclf = MLPClassifier(hidden_layer_sizes=(20, 10), activation = 'relu', solver = 'sgd', max_iter=3000, verbose=True) \n",
    "#mlpclf = MLPClassifier(hidden_layer_sizes=(10), activation = 'logistic', solver = 'sgd', max_iter=3000, verbose=True) \n",
    "#mlpclf = MLPClassifier(hidden_layer_sizes=(50), activation = 'logistic', solver = 'sgd', max_iter=3000, verbose=True)\n",
    "#mlpclf = MLPClassifier(hidden_layer_sizes=(20, 10), activation = 'logistic', solver = 'sgd', max_iter=3000, verbose=True) \n",
    "\n",
    "mlpclf.fit(X_train, y_train) \n",
    "B_shapes = [intercept.shape for intercept in mlpclf.intercepts_]\n",
    "print(\"The biases shapes are:\", B_shapes)\n",
    "W_shapes = [weights.shape for weights in mlpclf.coefs_]\n",
    "print('The weights shapes are:', W_shapes)\n",
    "\n",
    "y_pred_prob = mlpclf.predict_proba(X_test)\n",
    "print('The first 5 predicted probabilities:\\n', y_pred_prob[:5])\n",
    "y_pred = mlpclf.predict(X_test)\n",
    "print('The first 5 test data:\\n',X_test[:5])\n",
    "print('The first 5 predictions:\\n', y_pred[:5])\n",
    "print('The accuracy of the test data is: \\n', np.round(mlpclf.score(X_test, y_test),2))\n",
    "loss = mlpclf.loss_curve_\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ax[0].scatter(X_train[y_train == 1][:, 0], X_train[y_train == 1][:, 1], color='r', label='Training: Class 1')\n",
    "ax[0].scatter(X_train[y_train == 0][:, 0], X_train[y_train == 0][:, 1], color='b', label='Training: Class 0')\n",
    "ax[0].scatter(X_test[y_test == 1][:, 0], X_test[y_test == 1][:, 1], color='r', marker='x', label='Test: Class 1')\n",
    "ax[0].scatter(X_test[y_test == 0][:, 0], X_test[y_test == 0][:, 1], color='b', marker='x',label='Test: Class 0')\n",
    "ax[0].set_xlabel('X')\n",
    "ax[0].set_ylabel('y')\n",
    "ax[0].legend(loc='lower left')\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].plot(loss, label='Training Loss')\n",
    "ax[1].set_xlabel('Iterations')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].legend()\n",
    "ax[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('data_and_learning_curve_classification.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0bc0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
