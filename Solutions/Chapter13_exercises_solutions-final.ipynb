{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea868fc1",
   "metadata": {
    "id": "ea868fc1"
   },
   "source": [
    "#### Exercise 13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797cd034",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "797cd034",
    "outputId": "b495bb12-6c79-4264-ac49-740b2a708d65"
   },
   "outputs": [],
   "source": [
    "#Exercise 13.1\n",
    "import sympy as sp\n",
    "\n",
    "n = 2\n",
    "X = sp.symbols(f'X0:{n}')\n",
    "lamda = sp.symbols('lamda', real=True, positive=True)\n",
    "\n",
    "L = sum(sp.log(lamda *sp.exp(-lamda *x)) for x in X)\n",
    "\n",
    "dL_dlamda = sp.diff(L, lamda)\n",
    "\n",
    "lamda_hat = sp.solve(dL_dlamda, lamda)[0]\n",
    "print(lamda_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9888fcda",
   "metadata": {
    "id": "9888fcda"
   },
   "source": [
    "#### Exercise 13.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb9bd8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "id": "dfeb9bd8",
    "outputId": "c2162981-92e9-49a2-9679-4455b0e907dd"
   },
   "outputs": [],
   "source": [
    "#Exercise 13.2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_values = np.linspace(0, 2, 100)\n",
    "x_obs = [1, 1.5]\n",
    "\n",
    "lambda_best = 2/(x_obs[0]+x_obs[1])\n",
    "print('lambda_best is:',lambda_best)\n",
    "lambda_values = [lambda_best, 2, 3]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "for lambda_val in lambda_values:\n",
    "\n",
    "    pdf_values = lambda_val * np.exp(-lambda_val * x_values)\n",
    "    plt.plot(x_values, pdf_values, label=rf'$\\lambda={lambda_val}$')\n",
    "\n",
    "    pdf_obs = [lambda_val * np.exp(-lambda_val * x) for x in x_obs]\n",
    "    plt.scatter(x_obs, pdf_obs, label=rf'$\\lambda={lambda_val}$ at $x_1=1, x_2=1.5$', zorder=3)\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Exponential Distribution PDF for Different $\\lambda$ Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "for lambda_val in lambda_values:\n",
    "    print('For distribution with lamda value:',lambda_val)\n",
    "    pdf_obs = [lambda_val * np.exp(-lambda_val * x) for x in x_obs]\n",
    "    product = pdf_obs[0]*pdf_obs[1]\n",
    "    print('\\tProduct of probability density values is:',round(product,5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc0cf8b-c061-4662-a38b-42d332ca5d96",
   "metadata": {},
   "source": [
    "#### Exercise 13.3 - Linear regression with maximum likelihood Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qeSnGz3xBbFX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "qeSnGz3xBbFX",
    "outputId": "fa650a5f-2678-4b4f-c717-d826cf51fd5b"
   },
   "outputs": [],
   "source": [
    "#Exercise 13.3 - Linear regression with maximum likelihood Estimation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(421)\n",
    "n_data, d = 100, 1\n",
    "a = np.array([3,-2])\n",
    "X = np.random.rand(n_data, 1)\n",
    "X = np.c_[np.ones(n_data), X]\n",
    "noise = np.random.randn(n_data) * 2\n",
    "y = X @ a + noise\n",
    "\n",
    "a_mle = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "sigma2_mle = np.sum((y - X @ a_mle) ** 2) / (n_data-(d+1))\n",
    "print('MLE estimated a values are:', np.round(a_mle,2))\n",
    "print('MLE estimated sigma^2 = :', np.round(sigma2_mle,2))\n",
    "\n",
    "plt.scatter(X[:, 1], y)\n",
    "plt.plot(X[:, 1], X @ a_mle, color='red')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.savefig('LR_MLE.eps', format='eps', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ae5abf",
   "metadata": {
    "id": "95ae5abf"
   },
   "source": [
    "#### Exercise 13.4 - parts 1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d18ac7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "0d18ac7a",
    "outputId": "c84aab10-3187-48dd-b03c-6ccdb6880ffe"
   },
   "outputs": [],
   "source": [
    "#Exercise 13.4 - parts 1-3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(421)\n",
    "X = np.array([-2, 0, 2, 4])\n",
    "X = np.c_[np.ones(len(X)), X]\n",
    "\n",
    "y = np.array([3.6, 2.8, 1.6, 2])\n",
    "\n",
    "a_mle = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "sigma2_mle = np.round(np.sum((y - X @ a_mle) ** 2) / (len(y)-2), 2)\n",
    "\n",
    "print('MLE estimated a values are:', a_mle)\n",
    "print('MLE estimated sigma^2 = :', sigma2_mle)\n",
    "\n",
    "X_new = np.array([1, 1])\n",
    "y_new = a_mle.T @ X_new\n",
    "print('The prediction at X_new = 1 is:', y_new)\n",
    "\n",
    "plt.scatter(X[:, 1], y)\n",
    "plt.scatter(1, y_new, marker='x', color='black')\n",
    "plt.plot(X[:, 1], X @ a_mle, color='red')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c100038",
   "metadata": {
    "id": "1c100038"
   },
   "source": [
    "#### Exercise 13.4 - part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29dd694",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c29dd694",
    "outputId": "636b6310-df84-499d-8625-0575e253e6ed"
   },
   "outputs": [],
   "source": [
    "#Exercise 13.4 - part 4\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "print('The estimated a0 ={} and a1={}'.format(np.round(model.params[0],2), np.round(model.params[1],2)))\n",
    "\n",
    "sigma2 = model.scale\n",
    "print('The estimated sigma^2 =:', np.round(sigma2,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f2f2a2",
   "metadata": {
    "id": "22f2f2a2"
   },
   "source": [
    "#### Exercise 13.4 - part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39956a83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "39956a83",
    "outputId": "e796e27c-be1d-4628-c412-83002e4a2276"
   },
   "outputs": [],
   "source": [
    "#Exercise 13.4 - part 5 - CI for coefficients\n",
    "sl = 0.05  # 95% CI\n",
    "CI_params =model.conf_int(alpha=sl)\n",
    "print('The 95% confidence interval for a0 is:', np.round(CI_params[0,:], 2))\n",
    "print('The 95% confidence interval for a1 is:', np.round(CI_params[1,:], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c52d0ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c52d0ef",
    "outputId": "14e91e3d-4784-4821-8ad4-00510a16f4a0"
   },
   "outputs": [],
   "source": [
    "#Exercise 13.4 - part 5 - CI for sigma-squared\n",
    "import scipy.stats as stats\n",
    "\n",
    "sl = 0.05  # 95% CI\n",
    "df= 3\n",
    "chi2_lower = stats.chi2.ppf(1 - sl/2, df)\n",
    "chi2_upper = stats.chi2.ppf(sl/2, df)\n",
    "\n",
    "sigma2_lower = (df * sigma2) / chi2_lower\n",
    "sigma2_upper = (df * sigma2) / chi2_upper\n",
    "\n",
    "print('The 95% confidence interval for sigma^2 is:[{},{}]'.format(np.round(sigma2_lower,3), np.round(sigma2_upper,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ddfb33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93ddfb33",
    "outputId": "0062ee6a-94f2-4b01-e2d9-d852015f29da"
   },
   "outputs": [],
   "source": [
    "#Exercise 13.4 - part 5 - CI for new data point\n",
    "X_new = np.array([[1,1]])\n",
    "sl = 0.05  # 95% CI\n",
    "pred = model.get_prediction(X_new)\n",
    "pred_summary = pred.summary_frame(alpha=sl)\n",
    "\n",
    "y_pred = pred_summary['mean'].iloc[0] # Predicted mean. pred_summary[\"mean\"] returns a Pandas Series\n",
    "ci_lower, ci_upper = pred_summary['mean_ci_lower'].iloc[0], pred_summary['mean_ci_upper'].iloc[0]\n",
    "\n",
    "print('Prediction for X_new = 1 is {}'.format(np.round(y_pred,2)))\n",
    "print('The 95% confidence interval for the mean prediction is [{},{}]'.format(np.round(ci_lower,2), np.round(ci_upper,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea89bec",
   "metadata": {
    "id": "aea89bec"
   },
   "source": [
    "#### Exercise 13.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10ceb0c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "id": "c10ceb0c",
    "outputId": "9feb0b27-a794-469b-ebcf-935a6a4d9650"
   },
   "outputs": [],
   "source": [
    "#Exercise 13.5\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "C = 0.5 # [0.5, 1, 10, 100]\n",
    "\n",
    "np.random.seed(421)\n",
    "n_data = 50\n",
    "X = np.random.rand(n_data, 1)\n",
    "X = np.c_[np.ones(n_data), X]\n",
    "\n",
    "a = np.array([1,3])\n",
    "noise = np.random.randn(n_data) * C\n",
    "y = X @ a + noise\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "print('The estimated a0 ={} and a1={}'.format(np.round(model.params[0],2), np.round(model.params[1],2)))\n",
    "\n",
    "sigma2 = model.scale\n",
    "print('The estimated sigma^2 =:', np.round(sigma2,4))\n",
    "\n",
    "CI_params =model.conf_int(alpha=0.05)\n",
    "print('The 95% confidence interval for a0 is:', np.round(CI_params[0,:], 2))\n",
    "print('The 95% confidence interval for a1 is:', np.round(CI_params[1,:], 2))\n",
    "\n",
    "\n",
    "plt.scatter(X[:, 1], y)\n",
    "plt.plot(X[:, 1], X @ model.params, color='blue', label ='aX+noise')\n",
    "plt.plot(X[:, 1], X @ a, color='red', label = 'aX')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.savefig('LR.eps', format='eps', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb326db",
   "metadata": {
    "id": "5cb326db"
   },
   "source": [
    "#### Exercises 13.6 and 13.7 - sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc4003",
   "metadata": {
    "id": "aebc4003"
   },
   "outputs": [],
   "source": [
    "#Exercises 13.6 and 13.7 - sigmoid - a needed function\n",
    "def sigmoid(z):\n",
    "    return 1/(np.exp(-z)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8edb82",
   "metadata": {
    "id": "4d8edb82"
   },
   "outputs": [],
   "source": [
    "#Exercises 13.6 and 13.7 - gradient descent function\n",
    "def grad_descent_lr(X, y, weights, iters, epsilon):\n",
    "    for _ in range(iters):\n",
    "        linear_z = np.dot(X, weights)\n",
    "        print('z value =', linear_z)\n",
    "        y_predicted = sigmoid(linear_z)\n",
    "        print('The probabilities before iteration:', np.round(y_predicted,3))\n",
    "        initial_pred_labels = (y_predicted >= 0.5).astype(int)\n",
    "        print('Original predictions are:',initial_pred_labels)\n",
    "        error = y_predicted - y\n",
    "        dw = np.dot(X.T, error)\n",
    "        weights = weights - epsilon * dw\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e99a223",
   "metadata": {
    "id": "6e99a223"
   },
   "outputs": [],
   "source": [
    "#Exercises 13.6 and 13.7 - predict function\n",
    "def predict(X, weights, threshold):\n",
    "    linear_z = np.dot(X, weights)\n",
    "    probabilities = sigmoid(linear_z)\n",
    "    pred_labels = (probabilities >= threshold).astype(int)\n",
    "    return pred_labels, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2585b76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "id": "c2585b76",
    "outputId": "de4a44b7-ba2a-41bb-8253-35ce36dfd4f3"
   },
   "outputs": [],
   "source": [
    "#Exercise 13.6 - implementing logistic regression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.array([-1.5, -1, 0, 0.3])\n",
    "X = np.c_[np.ones(X.shape[0]), X]  # Add intercept (bias term) by inserting a column of ones\n",
    "y = np.array([0, 0, 1, 1])\n",
    "\n",
    "W = np.array([0.5, 0.4])\n",
    "learning_rate = 0.1\n",
    "num_iterations = 1\n",
    "theta = 0.5\n",
    "\n",
    "updated_W = grad_descent_lr(X, y, W, num_iterations, learning_rate)\n",
    "y_pred, probs = predict(X, updated_W, theta)\n",
    "\n",
    "print('The updated weights are:', np.round(updated_W,3))\n",
    "print('The probabilities after iteration are:', np.round(probs,3))\n",
    "print('Predictions are:', y_pred)\n",
    "print('True Labels are:', y)\n",
    "\n",
    "\n",
    "x_1d = np.linspace(-6, 6, 1000)\n",
    "x_2d = np.c_[np.ones(x_1d.shape[0]), x_1d]\n",
    "z = np.dot(x_2d, W)\n",
    "sigmoid_init = sigmoid(z)\n",
    "z_updated = np.dot(x_2d, updated_W)\n",
    "sigmoid_updated = sigmoid(z_updated)\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "plt.plot(x_1d, sigmoid_init, label = 'initial')\n",
    "plt.plot(x_1d, sigmoid_updated, label = 'updated')\n",
    "plt.xlabel('x',fontsize=12)\n",
    "plt.ylabel('y',rotation=0)\n",
    "plt.xticks(np.arange(-6, 7, step=1))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4F5-orqI_PZV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "id": "4F5-orqI_PZV",
    "outputId": "1bf652b0-5372-4747-b153-42ddca8fae75"
   },
   "outputs": [],
   "source": [
    "#Exercise 13.7 - implementing logistic regression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.array([-1, 0, 1, 3])\n",
    "X = np.c_[np.ones(X.shape[0]), X]  # Add intercept (bias term) by inserting a column of ones\n",
    "y = np.array([0, 0, 1, 1])\n",
    "\n",
    "W = np.array([-0.3, 0.2])\n",
    "learning_rate = 0.05\n",
    "num_iterations = 1\n",
    "theta = 0.5\n",
    "\n",
    "updated_W = grad_descent_lr(X, y, W, num_iterations, learning_rate)\n",
    "y_pred, probs = predict(X, updated_W, theta)\n",
    "\n",
    "print('The updated weights are:', np.round(updated_W,3))\n",
    "print('The probabilities after iteration are:', np.round(probs,3))\n",
    "print('Predictions are:', y_pred)\n",
    "print('True Labels are:', y)\n",
    "\n",
    "\n",
    "x_1d = np.linspace(-6, 6, 1000)\n",
    "x_2d = np.c_[np.ones(x_1d.shape[0]), x_1d]\n",
    "z = np.dot(x_2d, W)\n",
    "sigmoid_init = sigmoid(z)\n",
    "z_updated = np.dot(x_2d, updated_W)\n",
    "sigmoid_updated = sigmoid(z_updated)\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "plt.plot(x_1d, sigmoid_init, label = 'initial')\n",
    "plt.plot(x_1d, sigmoid_updated, label = 'updated')\n",
    "plt.xlabel('x',fontsize=12)\n",
    "plt.ylabel('y',rotation=0)\n",
    "plt.xticks(np.arange(-6, 7, step=1))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bae4af7",
   "metadata": {
    "id": "5bae4af7"
   },
   "source": [
    "#### Exercise 13.8 - generating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a1b0c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "40a1b0c2",
    "outputId": "e242516a-a59c-492b-fa18-c19e53dd5aa9"
   },
   "outputs": [],
   "source": [
    "#Exercise 13.8 - generating the data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(421)\n",
    "\n",
    "n_samples, n_features = 50, 2\n",
    "\n",
    "mean_0, cov_0 = [1, 1], [[1, 0.7], [0.7, 1]]\n",
    "mean_1, cov_1 = [2, 3], [[1, -0.5], [-0.5, 1]]\n",
    "\n",
    "X_0 = np.random.multivariate_normal(mean_0, cov_0, n_samples)\n",
    "X_1 = np.random.multivariate_normal(mean_1, cov_1, n_samples)\n",
    "X = np.vstack((X_0, X_1))\n",
    "y = np.hstack((np.zeros(n_samples), np.ones(n_samples)))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_0[:, 0], X_0[:, 1], label='Class 0')\n",
    "plt.scatter(X_1[:, 0], X_1[:, 1], label='Class 1')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18bd71d-476e-46b0-99c9-dd681fbcbb4c",
   "metadata": {
    "id": "af38f48a"
   },
   "source": [
    "#### Exercise 13.8 - Alternative 1- part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de33b2bd",
   "metadata": {
    "id": "de33b2bd"
   },
   "outputs": [],
   "source": [
    "#Exercise 13.8 - Alternative 1 - part 1\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b23336-41d3-4bed-a9e1-7eeaf2dcf16e",
   "metadata": {
    "id": "9b98af6a"
   },
   "source": [
    "#### Exercise 13.8 - Alternative 1 - part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22ae7d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c22ae7d0",
    "outputId": "1b9d20e5-927c-4a3f-aea5-4937b1d43730"
   },
   "outputs": [],
   "source": [
    "#Exercise 13.8 - Alternative 1 - part 2\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('Before normalisation:')\n",
    "print(f'X_train Mean: {np.mean(X_train, axis=0).round(2)}, X_train Std: {np.std(X_train, axis=0).round(2)}')\n",
    "print(f'X_test Mean: {np.mean(X_test, axis=0).round(2)}, X_test Std: {np.std(X_test, axis=0).round(2)}')\n",
    "print('After normalisation:')\n",
    "print(f'X_train_scaled Mean: {np.mean(X_train_scaled, axis=0).round(2)}, X_train Std: {np.std(X_train_scaled, axis=0).round(2)}')\n",
    "print(f'X_test_scaled Mean: {np.mean(X_test_scaled, axis=0).round(2)}, X_test Std: {np.std(X_test_scaled, axis=0).round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44ef25b-b75f-4230-9012-cb99a17f2f31",
   "metadata": {
    "id": "cc2cd429"
   },
   "source": [
    "#### Exercise 13.8 - - Alternative 1 - parts 3 & 4  Logistic Regression from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aac6eb9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aac6eb9",
    "outputId": "1667fa50-21c7-43c0-c4f9-157abb8c56d5"
   },
   "outputs": [],
   "source": [
    "#Exercise 13.8 - Alternative 1 - parts 3 & 4  Logistic Regression from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sklearn_model = LogisticRegression(penalty=None, solver='lbfgs')\n",
    "sklearn_model.fit(X_train_scaled, y_train)\n",
    "y_pred_sklearn = sklearn_model.predict(X_test_scaled)\n",
    "print('Model intercept is {} and coefficients are{}:'.format(sklearn_model.intercept_,sklearn_model.coef_))\n",
    "print('Sklearn logistic regression accuracy is:', accuracy_score(y_test, y_pred_sklearn))\n",
    "\n",
    "probabilities = sklearn_model.predict_proba(X_test_scaled)[:, 1]  # Probability of class 1\n",
    "threshold = 0.5 #can change this value\n",
    "y_pred_threshold = (probabilities >= threshold).astype(int)\n",
    "print('Sklearn logistic regression accuracy at threshold 0.5 is:', accuracy_score(y_test, y_pred_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357dcbe5-fcc0-46ac-ba33-8086f8d846f6",
   "metadata": {
    "id": "8cb64c8f"
   },
   "source": [
    "#### Exercise 13.8 - - Alternative 1 - parts 3 & 4  Logistic Regression from statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0d6023",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f0d6023",
    "outputId": "38138df9-3c96-4c4b-9868-b103c5371ba5"
   },
   "outputs": [],
   "source": [
    "#Exercise 13.8 - Alternative 1 - parts 3 & 4  Logistic Regression from from statsmodels\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train_scaled)\n",
    "X_test_sm = sm.add_constant(X_test_scaled)\n",
    "\n",
    "sm_model = sm.Logit(y_train, X_train_sm).fit(method='lbfgs')\n",
    "y_pred_probs_sm = sm_model.predict(X_test_sm)\n",
    "y_pred_sm = (y_pred_probs_sm >= 0.5).astype(int)\n",
    "# can change the 0.5 threshold value\n",
    "print('Model intercept & coefficients are:', sm_model.params)\n",
    "print('Statsmodels logistic regression accuracy is:', accuracy_score(y_test, y_pred_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5146025-927d-4c6c-a04c-5e2325dad769",
   "metadata": {},
   "source": [
    "#### Exercise 13.8 - Alternative 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d5db4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 797
    },
    "id": "1d7d5db4",
    "outputId": "2ae7d5bf-8155-4241-de04-9f026782ff4c"
   },
   "outputs": [],
   "source": [
    "#Exercise 13.8 - Alternative 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(421)\n",
    "\n",
    "n_samples, n_features = 50, 2\n",
    "\n",
    "mean_0, cov_0 = [1, 1], [[0.1, 0.7], [0.7, 0.1]]\n",
    "mean_1, cov_1 = [3, 3], [[0.1, -0.5], [-0.5, 0.1]]\n",
    "\n",
    "X_0 = np.random.multivariate_normal(mean_0, cov_0, n_samples)\n",
    "X_1 = np.random.multivariate_normal(mean_1, cov_1, n_samples)\n",
    "X = np.vstack((X_0, X_1))\n",
    "y = np.hstack((np.zeros(n_samples), np.ones(n_samples)))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_0[:, 0], X_0[:, 1], label='Class 0')\n",
    "plt.scatter(X_1[:, 0], X_1[:, 1], label='Class 1')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('Before normalisation:')\n",
    "print(f'X_train Mean: {np.mean(X_train, axis=0).round(2)}, X_train Std: {np.std(X_train, axis=0).round(2)}')\n",
    "print(f'X_test Mean: {np.mean(X_test, axis=0).round(2)}, X_test Std: {np.std(X_test, axis=0).round(2)}')\n",
    "print(\"After normalisation:\")\n",
    "print(f'X_train_scaled Mean: {np.mean(X_train_scaled, axis=0).round(2)}, X_train Std: {np.std(X_train_scaled, axis=0).round(2)}')\n",
    "print(f'X_test_scaled Mean: {np.mean(X_test_scaled, axis=0).round(2)}, X_test Std: {np.std(X_test_scaled, axis=0).round(2)}')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sklearn_model = LogisticRegression(penalty=None, solver='lbfgs')\n",
    "sklearn_model.fit(X_train_scaled, y_train)\n",
    "y_pred_sklearn = sklearn_model.predict(X_test_scaled)\n",
    "print('Model intercept is {} and coefficients are{}:'.format(sklearn_model.intercept_,sklearn_model.coef_))\n",
    "print('Sklearn logistic regression accuracy is:', accuracy_score(y_test, y_pred_sklearn))\n",
    "\n",
    "probabilities = sklearn_model.predict_proba(X_test_scaled)[:, 1]  # Probability of class 1\n",
    "threshold = 0.5 #can change this value\n",
    "y_pred_threshold = (probabilities >= threshold).astype(int)\n",
    "print('Sklearn logistic regression accuracy at threshold 0.5 is:', accuracy_score(y_test, y_pred_threshold))\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train_scaled)\n",
    "X_test_sm = sm.add_constant(X_test_scaled)\n",
    "\n",
    "sm_model = sm.Logit(y_train, X_train_sm).fit(method='lbfgs')\n",
    "y_pred_probs_sm = sm_model.predict(X_test_sm)\n",
    "y_pred_sm = (y_pred_probs_sm >= 0.5).astype(int)\n",
    "# can change the 0.5 threshold value\n",
    "print('Model intercept & coefficients are:', sm_model.params)\n",
    "print('Statsmodels logistic regression accuracy is:', accuracy_score(y_test, y_pred_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a701b-b507-4d67-90f4-a8c35cbe6b17",
   "metadata": {},
   "source": [
    "#### Exercise 13.8 - Alternative 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6Q2h49I3BhBW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "6Q2h49I3BhBW",
    "outputId": "025aabcc-c201-4ca7-802b-5293d036da8c"
   },
   "outputs": [],
   "source": [
    "#Exercise 13.8 - Alternative 3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(421)\n",
    "\n",
    "n_samples, n_features = 50, 2\n",
    "\n",
    "mean_0, cov_0 = [1, 1], [[10, 0.7], [0.7, 10]]\n",
    "mean_1, cov_1 = [3, 3], [[10, -0.5], [-0.5, 10]]\n",
    "\n",
    "X_0 = np.random.multivariate_normal(mean_0, cov_0, n_samples)\n",
    "X_1 = np.random.multivariate_normal(mean_1, cov_1, n_samples)\n",
    "X = np.vstack((X_0, X_1))\n",
    "y = np.hstack((np.zeros(n_samples), np.ones(n_samples)))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_0[:, 0], X_0[:, 1], label='Class 0')\n",
    "plt.scatter(X_1[:, 0], X_1[:, 1], label='Class 1')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('Before normalisation:')\n",
    "print(f'X_train Mean: {np.mean(X_train, axis=0).round(2)}, X_train Std: {np.std(X_train, axis=0).round(2)}')\n",
    "print(f'X_test Mean: {np.mean(X_test, axis=0).round(2)}, X_test Std: {np.std(X_test, axis=0).round(2)}')\n",
    "print('After normalisation:')\n",
    "print(f'X_train_scaled Mean: {np.mean(X_train_scaled, axis=0).round(2)}, X_train Std: {np.std(X_train_scaled, axis=0).round(2)}')\n",
    "print(f'X_test_scaled Mean: {np.mean(X_test_scaled, axis=0).round(2)}, X_test Std: {np.std(X_test_scaled, axis=0).round(2)}')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sklearn_model = LogisticRegression(penalty=None, solver='lbfgs')\n",
    "sklearn_model.fit(X_train_scaled, y_train)\n",
    "y_pred_sklearn = sklearn_model.predict(X_test_scaled)\n",
    "print('Model intercept is {} and coefficients are{}:'.format(sklearn_model.intercept_,sklearn_model.coef_))\n",
    "print('Sklearn logistic regression accuracy is:', accuracy_score(y_test, y_pred_sklearn))\n",
    "\n",
    "probabilities = sklearn_model.predict_proba(X_test_scaled)[:, 1]  # Probability of class 1\n",
    "threshold = 0.5 #can change this value\n",
    "y_pred_threshold = (probabilities >= threshold).astype(int)\n",
    "print('Sklearn logistic regression accuracy at threshold 0.5 is:', accuracy_score(y_test, y_pred_threshold))\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train_scaled)\n",
    "X_test_sm = sm.add_constant(X_test_scaled)\n",
    "\n",
    "sm_model = sm.Logit(y_train, X_train_sm).fit(method='lbfgs')\n",
    "y_pred_probs_sm = sm_model.predict(X_test_sm)\n",
    "y_pred_sm = (y_pred_probs_sm >= 0.5).astype(int)\n",
    "# can change the 0.5 threshold value\n",
    "print('Model intercept & coefficients are:', sm_model.params)\n",
    "print('Statsmodels logistic regression accuracy is:', accuracy_score(y_test, y_pred_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613745d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
