{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7fe3249-f3b9-4abb-bb2a-7454db8055a1",
   "metadata": {},
   "source": [
    "#### Listing 7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bbb4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listing 7.1\n",
    "import numpy as np\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "X = np.array([[3,2],[4,3],[2,1],[2,2],[4,2]])\n",
    "covX = np.cov(X.T)\n",
    "u = np.array([[2],[1]])\n",
    "\n",
    "print('The covariance matrix of X is:\\n', covX)\n",
    "print('The projections are:\\n', np.matmul(X, u))\n",
    "print('The variance of the projections is:', np.var(np.matmul(X, u), ddof=1))\n",
    "Var = (np.matmul(np.matmul(u.T, covX), u))\n",
    "print('The matrix at the end of the calculation is: ', Var)\n",
    "Var1 = Var[0,0]\n",
    "print('\\tand the value in the matrix is: ', Var1)\n",
    "display(Latex(f'$\\\\text{{So }} u^T \\\\Sigma u \\\\text{{ evaluates as: }} {str(Var1)}$'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9513429-4f16-41cb-b1da-656e80200a7b",
   "metadata": {},
   "source": [
    "#### Listing 7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aa7001",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Listing 7.2\n",
    "import sympy as sp\n",
    "\n",
    "A = sp.MatrixSymbol('A', 2,2)\n",
    "x = sp.MatrixSymbol('x', 2,1)\n",
    "dexpr = (x.T*A*x).diff(x)\n",
    "print(dexpr)\n",
    "print('A is:', A.as_explicit())\n",
    "print('x is:', x.as_explicit())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a5827-ed69-45a1-8695-1750f223e988",
   "metadata": {},
   "source": [
    "#### Listing 7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c8105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listing 7.3\n",
    "import sympy as sp\n",
    "\n",
    "a1, a2, a3, a4 = sp.symbols('a1 a2 a3 a4')\n",
    "A = sp.Matrix([[a1, a2], [a3, a4]])\n",
    "print(A)\n",
    "x1,x2 = sp.symbols('x1 x2')\n",
    "x = sp.Matrix([x1,x2])\n",
    "print(x)\n",
    "print(type((x.T*A*x).diff(x)))\n",
    "print(((x.T*A*x).diff(x)).shape)\n",
    "(x.T*A*x).diff(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9b7c83-5f42-41ec-87ba-6ff0e4108c68",
   "metadata": {},
   "source": [
    "#### Listing 7.4 - Problem Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9a0ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listing 7.4\n",
    "import sympy as sp\n",
    "\n",
    "n = sp.symbols('n')\n",
    "Sigma = sp.MatrixSymbol('Sigma', n, n)\n",
    "u1 = sp.MatrixSymbol(r'\\vec{u_1}', n, 1)\n",
    "lambda1 = sp.symbols('lambda_1')\n",
    "\n",
    "variance = u1.T * Sigma * u1 \n",
    "M = sp.OneMatrix(*(u1.T*u1).shape)\n",
    "constraint = lambda1 * (u1.T * u1 - M) \n",
    "print('Shape of the constructed matrix:\\n', M.shape)\n",
    "print('Value of the constructed matrix:', M)\n",
    "\n",
    "F1 = variance - constraint\n",
    "F1.diff(u1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d7712a-60b6-4134-8c19-3673ac3aca07",
   "metadata": {},
   "source": [
    "#### Listing 7.5 - PCA with and without normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76218f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listing 7.5\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(421)\n",
    "feature1 = np.random.normal(0, 0.5, 50)\n",
    "feature2 = np.random.normal(0, 5, 50)\n",
    "feature3 = np.random.normal(0, 10, 50)\n",
    "\n",
    "print(f'Feature1: Mean = {np.mean(feature1):.2f}, Standard Deviation = {np.std(feature1, ddof=1):.2f}')\n",
    "print(f'Feature2: Mean = {np.mean(feature2):.2f}, Standard Deviation = {np.std(feature2, ddof=1):.2f}')\n",
    "print(f'Feature3: Mean = {np.mean(feature3):.2f}, Standard Deviation = {np.std(feature3, ddof=1):.2f}')\n",
    "\n",
    "data = np.vstack((feature1, feature2, feature3)).T\n",
    "\n",
    "pca = PCA()\n",
    "pca_data = pca.fit_transform(data)\n",
    "explained_variance_without = pca.explained_variance_ratio_\n",
    "print('The eigenvalues (without normalisation) in descending order are:\\n',pca.explained_variance_)\n",
    "print(f'PC1: Mean = {np.mean(pca_data[:,0]):.2f}, Variance = {np.var(pca_data[:,0], ddof=1):.2f}')\n",
    "print(f'PC2: Mean = {np.mean(pca_data[:,1]):.2f}, Variance = {np.var(pca_data[:,1], ddof=1):.2f}')\n",
    "print(f'PC3: Mean = {np.mean(pca_data[:,2]):.2f}, Variance = {np.var(pca_data[:,2], ddof=1):.2f}')\n",
    "print('The principal components (without normalisation) are: \\n', pca.components_)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "normalised_data = scaler.fit_transform(data)\n",
    "means = np.mean(normalised_data, axis=0)\n",
    "std_devs = np.std(normalised_data, axis=0, ddof=1)\n",
    "print('The normalised data has mean: {}, and \\n standard deviation: {}'.format(means, std_devs))\n",
    "\n",
    "pca_normalised = PCA()\n",
    "pca_data_normalised = pca_normalised.fit_transform(normalised_data)\n",
    "explained_variance_with = pca_normalised.explained_variance_ratio_\n",
    "print('The eigenvalues (with normalisation) in descending order are:\\n',pca_normalised.explained_variance_)\n",
    "print(f'PC1: Mean = {np.mean(pca_data_normalised[:,0]):.2f}, Variance = {np.var(pca_data_normalised[:,0], ddof=1):.2f}')\n",
    "print(f'PC2: Mean = {np.mean(pca_data_normalised[:,1]):.2f}, Variance = {np.var(pca_data_normalised[:,1], ddof=1):.2f}')\n",
    "print(f'PC3: Mean = {np.mean(pca_data_normalised[:,2]):.2f}, Variance = {np.var(pca_data_normalised[:,2], ddof=1):.2f}')\n",
    "print('The principal components (with normalisation) are: \\n', pca_normalised.components_)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axs[0, 0].bar(range(1, len(explained_variance_without) + 1), explained_variance_without)\n",
    "axs[0, 0].set_xticks([0, 1, 2, 3, 4])\n",
    "axs[0, 0].set_title('Explained variance without normalisation')\n",
    "axs[0, 0].set_xlabel('PC Index')\n",
    "axs[0, 0].set_ylabel('Variance Ratio')\n",
    "\n",
    "axs[0, 1].bar(range(1, len(explained_variance_with) + 1), explained_variance_with)\n",
    "axs[0, 1].set_xticks([0, 1, 2, 3, 4])\n",
    "axs[0, 1].set_title('Explained variance with normalisation')\n",
    "axs[0, 1].set_xlabel('PC Index')\n",
    "axs[0, 1].set_ylabel('Variance Ratio')\n",
    "\n",
    "axs[1, 0].scatter(pca_data[:, 0], pca_data[:, 1])\n",
    "axs[1, 0].set_title('PCA visualisation without normalisation')\n",
    "axs[1, 0].set_xlabel('PC 1')\n",
    "axs[1, 0].set_ylabel('PC 2')\n",
    "\n",
    "axs[1, 1].scatter(pca_data_normalised[:, 0], pca_data_normalised[:, 1])\n",
    "axs[1, 1].set_title('PCA visualisation with normalisation')\n",
    "axs[1, 1].set_xlabel('PC 1')\n",
    "axs[1, 1].set_ylabel('PC 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig('PCA_with_without_normalisation.eps',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032d06aa-705c-4c05-9a08-caa732f726fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pca)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a74701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
