{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed0b7b1-088a-4491-90fc-4d003d7e1b76",
   "metadata": {
    "id": "664b2baf"
   },
   "source": [
    "#### Listing 13.1 - Computing the maximum likelihood estimate of mean and variance for a Gaussian distribution using SymPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927b82e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "927b82e4",
    "outputId": "e0ce3cee-7f26-4b9b-8b18-edead8cbc50b"
   },
   "outputs": [],
   "source": [
    "#Listing 13.1 - Computing the maximum likelihood estimate of mean and variance for a Gaussian distribution using SymPy\n",
    "import sympy as sp\n",
    "\n",
    "N = 4\n",
    "x = sp.symbols(f'x0:{N}')\n",
    "print('Data observations:', x)\n",
    "\n",
    "mu, sigma2 = sp.symbols('mu sigma2', real=True, positive=True)\n",
    "\n",
    "L = sum(-sp.log(sp.sqrt(2 * sp.pi * sigma2)) - ((xi - mu)**2 / (2 * sigma2)) for xi in x)\n",
    "\n",
    "dL_dmu = sp.diff(L, mu)\n",
    "dL_dsigma2 = sp.diff(L, sigma2)\n",
    "\n",
    "mu_hat = sp.solve(dL_dmu, mu)\n",
    "print('The maximum likelihood estimate of mu is:\\n', mu_hat)\n",
    "\n",
    "sigma2_hat = sp.solve(dL_dsigma2, sigma2)\n",
    "print('The maximum likelihood estimate of sigma2 is:\\n',sigma2_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80ac409-6519-4b25-8905-f53355c2e02c",
   "metadata": {
    "id": "40e203fb"
   },
   "source": [
    "#### Listing 13.2 - Example of MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81583de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "e81583de",
    "outputId": "001bb2f4-abc6-4bd2-8605-a1d706801967"
   },
   "outputs": [],
   "source": [
    "#Listing 13.2 - Example of MLE\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.array([0, 1])\n",
    "mu_mle, sigma_mle = np.mean(data), np.std(data, ddof=0)\n",
    "print('The maximum likelihood estimates, mu and sigma are: {} and {}.\\n'. format(mu_mle, sigma_mle))\n",
    "\n",
    "GaussDistrs = {'MLE': (mu_mle, sigma_mle), 'Gauss 1': (0, 1), 'Gauss 2': (1, 2)}\n",
    "print('GaussDistrs:',GaussDistrs)\n",
    "likelihoods = {key: stats.norm.pdf(data, mu, sigma) for key, (mu, sigma) in GaussDistrs.items()}\n",
    "print('likelihoods:',likelihoods)\n",
    "\n",
    "for key,lik in zip(likelihoods.keys(),likelihoods.values()):\n",
    "    print('For distribution:',key)\n",
    "    product = lik[0]*lik[1]\n",
    "    print('\\tProduct of probability density values is:',round(product,4))\n",
    "\n",
    "x = np.linspace(-3, 4, 1000)\n",
    "plt.figure(figsize=(8, 6))\n",
    "for label, (mu, sigma) in GaussDistrs.items():\n",
    "    plt.plot(x, stats.norm.pdf(x, mu, sigma), label=f'{label} (μ={mu:.1f}, σ={sigma:.1f})')\n",
    "\n",
    "offset = 0.01\n",
    "plt.scatter(data, [offset, offset], color='black')\n",
    "for i, x_val in enumerate(data):\n",
    "    plt.vlines(x_val, offset, max(lik[i] for lik in likelihoods.values()), color='gray', linestyle='dashed')\n",
    "    plt.hlines([lik[i] for lik in likelihoods.values()], -3, data[i], color='gray', linestyle='dashed')\n",
    "\n",
    "plt.xlim(-3, 4), plt.ylim(0, None)\n",
    "plt.xlabel('x', fontsize =\"15\")\n",
    "plt.ylabel(\"Probability Density\", fontsize =\"15\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('MLE.eps', format='eps', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dcc6ad-4927-4110-acd6-492bab9b33c9",
   "metadata": {
    "id": "7b5f4386"
   },
   "source": [
    "#### Listing 13.3 - Linear regression with maximum likelihood Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8725adc0",
   "metadata": {
    "id": "8725adc0",
    "outputId": "bef09762-c9a5-40dc-a5f9-d06daea1ffd4"
   },
   "outputs": [],
   "source": [
    "#Listing 13.3 - Linear regression with maximum likelihood Estimation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(421)\n",
    "n_data, d = 50, 1\n",
    "a = np.array([1,3])\n",
    "X = np.random.rand(n_data, 1)\n",
    "X = np.c_[np.ones(n_data), X]\n",
    "noise = np.random.randn(n_data) * 0.25\n",
    "y = X @ a + noise\n",
    "\n",
    "a_mle = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "sigma2_mle = np.sum((y - X @ a_mle) ** 2) / (n_data-(d+1))\n",
    "print('MLE estimate of the regression coefficient vector:', np.round(a_mle,2))\n",
    "print('MLE estimate of sigma^2 = :', np.round(sigma2_mle,2))\n",
    "\n",
    "plt.scatter(X[:, 1], y)\n",
    "plt.plot(X[:, 1], X @ a_mle, color='red')\n",
    "plt.xlabel('X', fontsize =\"12\")\n",
    "plt.ylabel('y', fontsize =\"12\")\n",
    "plt.savefig('LR_MLE.eps', format='eps', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f16678d-4fd4-48b8-90b8-b37203de3e2b",
   "metadata": {
    "id": "b9224342"
   },
   "source": [
    "#### Listing 13.4 - Sampling distribution of the linear regression estimators: a - manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2eb2ad",
   "metadata": {
    "id": "ad2eb2ad"
   },
   "outputs": [],
   "source": [
    "#Listing 13.4 - Sampling distribution of the linear regression estimators: set up\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X = np.array([1,2,3,4,5])\n",
    "X = sm.add_constant(X)\n",
    "y = np.array([2.4,2,1.6,1,0.4])\n",
    "\n",
    "n_data = len(y)\n",
    "d = 1\n",
    "df = n_data - (d+1)\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00154997-6e20-4d4b-bd37-ad462d5c8b38",
   "metadata": {
    "id": "85f04076"
   },
   "source": [
    "#### Listing 13.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb41a6d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fb41a6d1",
    "outputId": "7204e28f-1509-4171-9369-b4c6acf8c88f"
   },
   "outputs": [],
   "source": [
    "#Listing 13.5 - Sampling distribution of the linear regression estimators: \n",
    "# finding confidence interval for a manually\n",
    "XTX_inv = np.linalg.inv(X.T @ X)\n",
    "a_mle = XTX_inv @ X.T @ y\n",
    "print('The estimated a0 ={} and a1={}'.format(np.round(a_mle[0],2), np.round(a_mle[1],2)))\n",
    "sigma2_mle = np.sum((y - X @ a_mle) ** 2) / (n_data-(d+1))\n",
    "print('The estimated sigma^2 =:', np.round(sigma2_mle,4))\n",
    "\n",
    "SE_a0 = np.sqrt(sigma2_mle * XTX_inv[0, 0])\n",
    "SE_a1 = np.sqrt(sigma2_mle * XTX_inv[1, 1])\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df)\n",
    "CI_a0 = (np.round((a_mle[0] - t_critical * SE_a0), 2), np.round((a_mle[0] + t_critical * SE_a0),2))\n",
    "CI_a1 = (np.round((a_mle[1] - t_critical * SE_a1), 2), np.round((a_mle[1] + t_critical * SE_a1),2))\n",
    "\n",
    "print(f'95% Confidence Interval for a0: {CI_a0}')\n",
    "print(f'95% Confidence Interval for a1: {CI_a1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a48a2ad-cfe0-47aa-9db6-1ce8a7a55fbb",
   "metadata": {
    "id": "b6705666"
   },
   "source": [
    "#### Listing 13.6 - Sampling distribution of the linear regression estimators: a - statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b0e1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e28b0e1a",
    "outputId": "dd1db769-43c0-40d9-e4b8-cc1261be82f0"
   },
   "outputs": [],
   "source": [
    "#Listing 13.6 - Sampling distribution of the linear regression estimators: \n",
    "# findingconfidence interval for a using statsmodels\n",
    "model = sm.OLS(y, X).fit()\n",
    "print('The estimated a0 ={} and a1={}'.format(np.round(model.params[0],2), np.round(model.params[1],2)))\n",
    "\n",
    "sigma2 = model.scale\n",
    "print('The estimated sigma^2 =:', np.round(sigma2,4))\n",
    "\n",
    "CI_params = model.conf_int(alpha=0.05)\n",
    "print('The 95% confidence interval for a0 is:', np.round(CI_params[0,:], 2))\n",
    "print('The 95% confidence interval for a1 is:', np.round(CI_params[1,:], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62e4eff-ebbb-44c0-ac4c-99a633124977",
   "metadata": {
    "id": "99bfe2ba"
   },
   "source": [
    "#### Listing 13.7 - Sampling distribution of the linear regression estimators: sigma2 - statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e9622a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98e9622a",
    "outputId": "1623102d-aabf-4d5f-c4d5-292cc312662c"
   },
   "outputs": [],
   "source": [
    "#Listing 13.7 - Sampling distribution of the linear regression estimators:\n",
    "# finding sigma2 using statsmodels\n",
    "chi2_lower = stats.chi2.ppf(1 - alpha/2, df)\n",
    "chi2_upper = stats.chi2.ppf(alpha/2, df)\n",
    "\n",
    "sigma2_lower = (df * sigma2) / chi2_lower\n",
    "sigma2_upper = (df * sigma2) / chi2_upper\n",
    "\n",
    "print('The 95% confidence interval for sigma^2 is:[{},{}]'.format(np.round(sigma2_lower,3), np.round(sigma2_upper,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb79484-4fb1-4b17-abed-fd0fb4bcb556",
   "metadata": {
    "id": "1f4109af"
   },
   "source": [
    "#### Listing 13.8 - Sampling distribution of the linear regression: prediction - statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b66611",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34b66611",
    "outputId": "fe187f92-7f07-4578-a7f6-e7746f60f2f2"
   },
   "outputs": [],
   "source": [
    "#Listing 13.8 - Sampling distribution of the linear regression: \n",
    "# finding a new prediction using statsmodels\n",
    "X_new = np.array([[1,3.5]])\n",
    "pred = model.get_prediction(X_new)\n",
    "pred_summary = pred.summary_frame(alpha=0.05)\n",
    "\n",
    "print(pred_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804fcd0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "804fcd0b",
    "outputId": "0fc9fdea-1e03-4826-e2dc-214a5f4f0a4f"
   },
   "outputs": [],
   "source": [
    "#Additional part for Listing 13.8\n",
    "y_pred = pred_summary['mean'].iloc[0]\n",
    "ci_lower, ci_upper = pred_summary[\"mean_ci_lower\"].iloc[0], pred_summary[\"mean_ci_upper\"].iloc[0]\n",
    "\n",
    "print('Prediction for X_new = 3.5 is {}'.format(np.round(y_pred,2)))\n",
    "print('The 95% confidence interval for the mean prediction is [{},{}]'.format(np.round(ci_lower,2), np.round(ci_upper,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5054eb",
   "metadata": {
    "id": "1d5054eb"
   },
   "source": [
    "#### Logistic regression from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca0d89",
   "metadata": {
    "id": "05ca0d89"
   },
   "outputs": [],
   "source": [
    "#Function needed for Listing 13.9\n",
    "def sigmoid(z):\n",
    "    return 1/(np.exp(-z)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9c5ddb-1c33-49d0-85fd-e46521e4375a",
   "metadata": {
    "id": "d8b38e12"
   },
   "source": [
    "#### Listing 13.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20977cc",
   "metadata": {
    "id": "d20977cc"
   },
   "outputs": [],
   "source": [
    "#Listing 13.9\n",
    "def predict(X, weights):\n",
    "    linear_z = np.dot(X, weights)\n",
    "    print('z value =', linear_z)\n",
    "    probabilities = sigmoid(linear_z)\n",
    "\n",
    "    return  probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb148e70-0bc9-483a-948e-f05324da0592",
   "metadata": {
    "id": "c8bec128"
   },
   "source": [
    "#### Listing 13.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49355b29",
   "metadata": {
    "id": "49355b29"
   },
   "outputs": [],
   "source": [
    "#Listing 13.10\n",
    "def grad_descent_lr(X, y, weights, iters, epsilon):\n",
    "    for _ in range(iters):\n",
    "        y_predicted = predict(X, weights)\n",
    "        print('The probabilities before iteration:', np.round(y_predicted,3))\n",
    "        initial_pred_labels = (y_predicted >= 0.5).astype(int)\n",
    "        print('Original predictions are:',initial_pred_labels)\n",
    "        error = y_predicted - y\n",
    "        dw = np.dot(X.T, error)\n",
    "        weights = weights - epsilon * dw\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caca9cc-a168-46d2-bc0a-955785de5fb6",
   "metadata": {
    "id": "4c891a06"
   },
   "source": [
    "#### Listing 13.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d824310c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d824310c",
    "outputId": "f54b5ef3-b01d-48a8-ea64-7c08ee2800b6"
   },
   "outputs": [],
   "source": [
    "#Listing 13.11\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([-1.5, -1, 0, 0.3])\n",
    "X = np.c_[np.ones(X.shape[0]), X]\n",
    "y = np.array([0, 0, 1, 1])\n",
    "\n",
    "W = np.array([0.5, 0.4])\n",
    "learning_rate = 0.1\n",
    "num_iterations = 1\n",
    "\n",
    "updated_W = grad_descent_lr(X, y, W, num_iterations, learning_rate)\n",
    "probs = predict(X, updated_W)\n",
    "pred_labels = (probs >= 0.5).astype(int)\n",
    "\n",
    "print('The updated weights are:', np.round(updated_W,3))\n",
    "print('The new probabilities are:', np.round(probs,3))\n",
    "print('New predictions are:', pred_labels)\n",
    "print('True Labels are:', y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a6a3ac-d539-45b0-8905-0eca1f8df90f",
   "metadata": {
    "id": "57b48db7"
   },
   "source": [
    "#### Listing 13.12 - Implement logistic regression using existing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df04bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "f9df04bd",
    "outputId": "84efe6bd-ca0d-410e-9270-47d33324b8b1"
   },
   "outputs": [],
   "source": [
    "#Listing 13.12 - Implement logistic regression using existing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(421)\n",
    "n_samples, n_features = 50, 2\n",
    "\n",
    "mean_0, cov_0 = [1, 2], [[1, 0.5], [0.5, 1]]\n",
    "mean_1, cov_1 = [3, 3], [[1, -0.3], [-0.3, 1]]\n",
    "\n",
    "data1 = np.random.multivariate_normal(mean_0, cov_0, n_samples)\n",
    "data2 = np.random.multivariate_normal(mean_1, cov_1, n_samples)\n",
    "X = np.vstack((data1, data2))\n",
    "y = np.hstack((np.zeros(n_samples), np.ones(n_samples)))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(data1[:, 0], data1[:, 1], label='Class 0')\n",
    "plt.scatter(data2[:, 0], data2[:, 1], label='Class 1')\n",
    "plt.xlabel('x1', fontsize =\"15\")\n",
    "plt.ylabel('x2', fontsize =\"15\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('data.eps', format='eps', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8d51f8-2fee-4640-9bc5-f32f99ba8e6c",
   "metadata": {
    "id": "86c15a87"
   },
   "source": [
    "#### Listing 13.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6231928f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6231928f",
    "outputId": "99c15bba-a1cf-40ff-b0d9-813db8ef1834"
   },
   "outputs": [],
   "source": [
    "#Listing 13.13\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('Before normalisation:')\n",
    "print(f'X_train Mean: {np.mean(X_train, axis=0).round(2)}, X_train Std: {np.std(X_train, axis=0).round(2)}')\n",
    "print(f'X_test Mean: {np.mean(X_test, axis=0).round(2)}, X_test Std: {np.std(X_test, axis=0).round(2)}')\n",
    "print('After normalisation:')\n",
    "print(f'X_train_scaled Mean: {np.mean(X_train_scaled, axis=0).round(2)}, X_train Std: {np.std(X_train_scaled, axis=0).round(2)}')\n",
    "print(f'X_test_scaled Mean: {np.mean(X_test_scaled, axis=0).round(2)}, X_test Std: {np.std(X_test_scaled, axis=0).round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd20a98-91f6-4f03-a6f3-ec50d2669388",
   "metadata": {
    "id": "b0f66cc3"
   },
   "source": [
    "#### Listing 13.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cc9527",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8cc9527",
    "outputId": "2a2708b5-6f63-4b2c-f4a8-843384ae666a"
   },
   "outputs": [],
   "source": [
    "#Listing 13.14\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sklearn_model = LogisticRegression(penalty=None, solver='lbfgs', tol=1e-8)\n",
    "sklearn_model.fit(X_train_scaled, y_train)\n",
    "y_pred_sklearn = sklearn_model.predict(X_test_scaled)\n",
    "print('Model intercept is {} and \\n coefficients are{}'.format(sklearn_model.intercept_,sklearn_model.coef_))\n",
    "print('Sklearn logistic regression accuracy is:', accuracy_score(y_test, y_pred_sklearn))\n",
    "\n",
    "probabilities = sklearn_model.predict_proba(X_test_scaled)[:, 1]\n",
    "threshold = 0.5\n",
    "y_pred_threshold = (probabilities >= threshold).astype(int)\n",
    "print('Sklearn logistic regression accuracy at threshold 0.5 is:', accuracy_score(y_test, y_pred_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642e79eb-9c90-4222-9e04-6edacdd20130",
   "metadata": {
    "id": "dd0787c7"
   },
   "source": [
    "#### Listing 13.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af52eeb5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af52eeb5",
    "outputId": "3cc17ed8-7332-48f1-f639-ce45cfe01f88"
   },
   "outputs": [],
   "source": [
    "#Listing 13.15\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train_scaled)\n",
    "X_test_sm = sm.add_constant(X_test_scaled)\n",
    "\n",
    "sm_model = sm.Logit(y_train, X_train_sm).fit(method='lbfgs')\n",
    "y_pred_probs_sm = sm_model.predict(X_test_sm)\n",
    "y_pred_sm = (y_pred_probs_sm >= 0.5).astype(int)\n",
    "print('Model intercept & coefficients are:\\n', sm_model.params)\n",
    "print('Statsmodels logistic regression accuracy is:', accuracy_score(y_test, y_pred_sm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda6e8f-e861-4ad6-9519-0529a604c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listing 13.15 - extra\n",
    "conf_intervals = sm_model.conf_int(alpha=0.05)\n",
    "print(conf_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f890df2-a055-4040-b4e5-3cc58c907aca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
